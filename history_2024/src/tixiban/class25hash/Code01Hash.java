package tixiban.class25hash;

/**
 * 哈希函数知识
 * 本章没有code,因为资源限制类题目需要的输入条件过多,且实现的代码量巨大,面试中这类问题一般是和面试官聊解法,不涉及代码实现.
 *
 */
public class Code01Hash {
    /**
     * 哈希函数举例:SHA-256、SHA-512、MD5、MD256等
     * 每个哈希函数实现原理都有些不同
     */

    /**
     * 哈希函数特性
     * 1、输入输出域范围:输入域无穷大(例如任意字符串),输出域相对有限(例如0~2^64-1,整数).
     * 1.1、哈希碰撞:因为输入域无穷,输出域有限,所以不同输入可能导致相同输出,这种情况叫哈希碰撞.
     * 2、一致性:没有任何随机成分,相同输入一定导致相同输出.
     * 3、离散性/均匀性:即便再相似的不同输入,得到的输出值也会几乎均匀地分布在输出域上
     */

    /**
     * 哈希表
     *
     * 由哈希函数决定一个元素的下标
     * 哈希表有初始长度,假设为n,哈希表的n个位置其实是n个桶.来了一个元素,用哈希函数算出一个结果,模n,得到在哈希表里的下标,挂到下标对应的桶上.
     * 因为哈希函数是均匀的,所以模完n也是均匀的.
     *
     * 既然哈希表每个下标是个桶,那么随着桶长度越来越长,哈希表会越来越慢.
     * 因此有了扩容机制,例如哈希表初始长度17,每个桶长度到达6就扩容:长度*2,每个元素重新计算哈希值挂在新的桶上.
     *
     * 既然要时不时扩容,还要重新计算哈希,那么怎么保证哈希表每次插入都是O(1)?
     * 答:因为扩容和重新哈希的复杂度平均到每一次插入是O(1).证明:
     * 最差情况,哈希表初始长度为1,桶长度达到2就扩容,
     * 那么哈希表在插入第2、3、5、9、17、33...个的时候要扩容(2^(k-1)+1),对应的复杂度为O(2),O(3),O(5),O(9),O(17),O(33)...
     * 等比数列,累加从插入第1个到第n个的全部复杂度,O(N),平均到每次O(N)/N=O(1)
     *
     */

    /**
     * 布隆过滤器
     * 用途:黑名单.布隆过滤器一定有失误率(不在黑名单里的可能被误黑,已经在黑名单里的不会被误白),但是可以通过设计让失误率降低.
     * 原理:
     * 准备m个空间,k个哈希函数.
     * 加黑名单:每个str进来,用k个哈希函数计算k个哈希值,都模m,得到k个下标,把m里对应k个下标描黑.
     * 查黑名单:每个str进来,用k个哈希函数计算k个哈希值,都模m,得到k个下标,如果m中k个下标都是黑的说明str在黑名单,但凡有一个不黑,就不在黑名单(哈希函数输入相同一定输出相同).
     *
     * 布隆过滤器的关键,就是根据业务要求的样本量n、失误率p,来设计空间m取多长,哈希函数k取几个.
     *
     * 布隆过滤器要开多大只由1.样本量n、2.失误率p决定,跟单样本大小无关,因为布隆过滤器计算哈希后不存原样本,只把哈希对应的下标描黑,描黑的操作一个bit就够了.
     * m取太小的话,很快就全被描黑,全黑就意味着后面全会误黑,失误率高,m取太大可能浪费空间.
     * 公式1:见截图
     *
     * 布隆过滤器用多少个哈希函数除了跟n、p有关,还跟m有关
     * k取太小会因为采样不足导致失误率高,k取太大那么每次描黑的位数也多,会让m迅速耗尽,同样导致失误率高.
     * 公式2:见截图
     *
     * 怎么跟面试官聊布隆过滤器?
     * 面试官想做个类似黑名单的功能,那么先问面试官样本量多大,假设n=100亿,再问允许有失误率吗?如果允许,那么就是在考布隆过滤器,假设失误率p=0.0001万分之一,
     * 1.先根据公式1算出理论大小m,是bit的数量,换算成Byte大约是17GB
     * 2、跟面试官argue:满足样本量和失误率的理论大小m=17GB,能不能充裕一点给20G?这样就能把失误率降的更低.如果能,那么就有了实际大小M=20GB
     * 3、把实际M带入公式2算出哈希函数个数=12.7,向上取整,实际哈希函数个数K=13
     * 4、把实际M、实际K、样本量n带入公式3,得到实际失误率P,P一定比要求的p小.
     *
     * 问题:如何得到13个哈希函数?
     * 找一个哈希函数a,和另一个哈希函数b,
     * 那么 i*a + b ,i从1到13,就是互相独立的13个哈希函数(线性函数里的线性无关?)
     *
     * 布隆过滤器其他应用:
     * HDFS (分布式文件系统,大数据用的)
     * 如果每台机器都维护一个布隆过滤器,那么找一个文件abc就可以只从过滤器命中的机器找,不用全部机器遍历了.
     *
     * 说到底都是用来过滤.
     *
     */

    /**
     * 一致性哈希
     *
     * 分布式存储最常见的结构
     * 1.哈希域变成环的设计
     * 2.虚拟节点技术
     *
     * 解决的问题:用哈希函数分片存储,怎么横向扩展机器的问题
     *
     * 例如一开始有3台机器,来一条数据根据哈希key计算哈希,模3算出该存哪台机器.
     *
     * 不用一致性哈希:
     * 现在要增加一台,那么全量数据要重新计算哈希重新取模重新存储,数据迁移的代价是全量的.
     *
     * 用一致性哈希:
     *
     * 1.哈希域变成环的设计
     * 把哈希域(例如0~2^64-1)在逻辑上设计成环状,3台机器用唯一标识(ip、hostName、mac地址等)计算哈希后存到环的对应位置.
     * 来一条数据,用业务的哈希key计算哈希,存到这个哈希值在环上顺时针遇到的第一台机器上.
     * 因此环上每台机器所管辖的范围是:m1~m2范围存到m2,m2~m3范围存到m3,m3~m1范围存到m1
     * 扩展机器时,假设m4计算哈希后位于m3和m1之间,那么只需要把m3~m4范围的这部分数据迁移到m4上即可(m4~m1范围本来就存在m1上,现在依然存在m1).
     *
     * 1.1.怎么找顺时针遇到的第一台?
     * 所有机器按照哈希值排序后形成一个数组,来一个数据计算哈希,在数组中找大于这个哈希的最左的位置.
     * 例如哈希值m1=7,m2=64,m3=9,那么排序得到数组[(7,m1),(9,m3),(64,m2)].来一个数据计算哈希=56,找到>56最左的位置(64,m2),就存到m2上.
     *
     * 几个关键问题:
     * a.负载不均.初始3台机器可能算出的哈希值很接近,不在环上均匀分布,导致两台机器之间的范围有的大有的小,对应管辖的机器负载就有大有小.
     *   问:哈希函数不是有均匀性吗?为什么还分布不均匀?
     *   答:哈希函数的均匀性指的是数据量很大的情况下,去观察哈希域上的值,几乎均匀分布.并不是输入3个数据就能3等分.
     * b.即便初始3台机器的均匀性解决了,那么再加一台机器立马又不均匀了.
     *
     * 2.虚拟节点技术
     * (利用哈希函数均匀性,通过扩大样本量来实现均匀)
     * 给m1分配1000个节点[a1,a2...a1000],给m2分配1000个节点[b1,b2...b1000],给m3分配1000个节点[c1,c2...c1000],各自有路由表记录机器有哪几个节点,以及节点属于哪个机器.
     * 把这3000个节点计算哈希上环,那么这3000个节点一定是均匀分布的(如果3000个不均匀就用30000个),
     * 按同样的顺时针方法,归属到a类1000个节点上的数据都归属到m1.3000个节点均匀分布后,3台机器的负载也一定均衡.
     * 新加入一台机器m4时,也分配1000个节点[d1,d2...d1000],计算哈希,上到环上,那么这1000个节点一定也均匀分布,
     * 按同样的迁移方式,差不多会分别从a类、b类、c类节点上分别要来1/12的数据,数据迁移的代价是1/4.
     * 如果有机器挂了,从机继承路由表.
     *
     * 虚拟节点技术不仅能实现负载均衡,还能实现负载管理:
     * 假如m1机器性能强,m2性能弱,那么可以给m1分配1500个节点,给m2分配500个节点.
     *
     *
     * 一致性哈希运用在云集群的产品上.例如redis集群.每个云产品有自己的一致性哈希方案.
     *
     * 一致性哈希计算的时候不涉及取模.
     *
     */

}
